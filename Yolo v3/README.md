# Yolo
Yolo는 **You Only Look Once**의 약자로 Object detection 분야에서 많이 알려진 모델이다. YOLO가 등장하기 이전에도 딥러닝 모델을 이용하여 객체 탐지를 수행하는 방법은 있었다. 대표적으로 DPM과 R-CNN이 존재했다. 하지만 YOLO는 기존 모델들 보다 더 높은 정확도를 추구하는 것이 아닌, 근접한 정확도를 가지면서 더 많은 양의 이미지를 처리할 수 있는 **실시간 객체 탐지**를 하고자 등장했다. Yolo는 등장 시점부터 지금까지 여러 개발자가 연구를 이어가며 지금까지 버전이 업그레이드 되고 있다. Yolo는 버전마다 장단점이 있으나 대체로 업그레이드 될 수록 더 좋은 성능을 보인다고 할 수 있다.  


<br><br>



# Yolo를 선택한 이유
이번 프로젝트를 통하여 개발하고자 하는 **개인화 패션 추천 서비스**는 이미 다른 사람들에 의하여 상용화되어 서비스 중인 상황이다. 따라서 현재 제공되고 있는 그러한 서비스들과 차별되는 기능을 구상하게 되었다. 차별화된 기능 중 하나로써, 사진 뿐만 아니라 동영상에 있는 옷을 인식하여 해당 옷이 어떤 것이며 그 옷과 사람들이 주로 매칭하는 옷은 무엇인지 추천하는 서비스를 제공하고자 하였다. 이러한 서비스를 구현하기 위해서는 사진이나 이미지 뿐만 아니라 움직이는 영상에서도 객체를 탐지하는 기능이 필요하였으며, 실시간으로 객체를 탐지하는 OSS중에서 최고의 속도와 정확도를 보여주는 **Yolo**를 선택하게 되었다.  

<br><br>


# Yolo의 버전은?
Yolo는 버전이 업그레이드 되면서 성능 또한 향상되어 왔다. 버전별 업그레이드 변천사는 다음과 같다.

+ Yolo v2부터 Anchor Box가 도입되었으며, K-means로 Optimal한 크기와 개수를 정해준다. 
+ v1과 달리, v2는 FC Layer가 사라져, 다양한 Size의 Input을 넣을 수 있게 되었다.
+ v3에서는 Yolo v2까지의 고질적인 문제였던 Small Object를 잘 못찾는다는 것을 3 scale로 예측하는 multi scale의 도입으로 작은 물체 탐지 문제를 완화하였다.
+ v4부터 Mosaic, MixUp 등 다양한 Augmentation을 적용하여 성능을 향상시켰다.

+ 또한, v4는 전 버전들과 달리 CSP Layer를 활용하여 정확도는 향상시키되, 속도를 줄이는데 큰 역할을 했다.

+ v4까지 Darknet 기반 Backbone을 사용한 것과 달리, v5부터 Pytorch로 구현된 Backbone을 사용하였다.

+ v6부터는 기존 3개의 scale로 Detection하던 것에서 4개로 늘어나 더 다양한 Size의 Object를 잘 Detection 하게 되었다.

+ v7은 현재 릴리즈된 버전 중에서 가장 최신으로, 5 ~ 160 FPS 범위의 속도와 정확도 측면에서 현재까지 나온 모든 Object Detector의 성능을 능가한다.

버전별 업그레이드 변천사를 볼 때, 최신 버전인 v7을 선택하는 것이 가장 좋다고 할 수 있다. 하지만 버전을 선택할 때 라이선스 문제도 고려해야 한다.  

<br><br>

# Yolo 라이선스

<img width="1000" height="350" src="yolo_license.png"/>
<br><br>


darknet 기반이였던 yolo v1~v3 까지는 상업적 사용이 가능한 public 라이선스였던 반면,
pytorch로 구현된 ultralytics의 yolo v5 구현은 GPL 3.0 라이선스이다.
WongKinYiu의 repo에 구현된 yolo v7 버전 또한 ultralytics를 base로 개발되었기 때문에, GPL 라이선스가 전염되었다.

즉, 가장 많이 사용되는 ultralytics/WongKinYiu의 소스코드를 기반으로 개발하여 제품을 개발할 경우 소스코드 전체 배포의 의무가 있다.

이처럼 좋은 성능을 보여주는 최신 버전의 Yolo를 사용한다면 GPL 3.0 라이선스를 따라야 하며, 실제로 ultralytics repo의 이슈에 이러한 질문글이 등장하기도 한다.
<br><br>

    1) 상업적 사용 제약사항 완화를 위한 GPL3.0 라이선스 정책 완화 요청

    2) Kaggle 제출을 위한 GPL3.0 라이선스 정책 완화 요청
<br>

1번 질문의 경우 비전관련 솔루션 업체에서 yolo를 사용해 솔루션을 개발하더라도,
GPL 라이선스로 인해 솔루션 형태의 제품을 판매할 수가 없다는것이다.
다시 말해, 소스코드를 공개하는것은 gpl yolo 소스코드 이외에도 회사의 노력으로 개발된 기술들이 경쟁업체에 노출될 수 밖에 없기 때문에, GPL3.0의 강력한 라이선스 정책을 완화해달라는 요청이다.

ulgralytics의 glenn-jocher는 더 많은 사람들과 학생들이 yolo를 접하고 개선해 나갈 수 있게 GPL3.0을 적용했으며, 변경 계획은 없다고 확고하게 답한다.

2번 질문의 경우도 1번 질문과 비슷한 내용이다. Kaggle 경진대회에 yolo v5를 사용하면 좋은 성적을 달성할 수 있지만 Kaggle의 GPL 라이선스의 프로젝트는 제출금지 제약사항으로 인해 yolo v5의 인기에 악영향을 끼치고 있다는 것이다.

여기서도 glenn-jocher 는 라이선스 정책에 대해서는 1번 질문의 답변과 같이 단호한 입장이다.
<br>

따라서, 추후에 GPL 라이선스 기반의 Yolo 버전을 사용할 때 생기는 문제점을 해결할 수 있는 연구와 개발이 진행된다면 최신 버전의 Yolo를 사용하는 것을 고려할만 하다.
하지만, 현재 개발 단계에서는 MIT 라이선스의 **v3** 버전을 사용하기로 한다. 이는 v3 버전이 상업적으로 사용함에 있어 문제가 되지 않으며, 오랜 기간 동안 많은 개발자들에 의해 여러 피드백을 받아왔기 때문에 보다 안정적이기 때문이다.
<br><br>

# Yolo v3를 이용한 구현 단계 예상

구현 단계에서 핵심적인 요소는 다음과 같다.

    객체를 인식한다.

    인식한 객체를 분할한다.

    분할한 데이터와 패션 데이터셋을 접목하여 해당 의류를 분류해낸다.


따라서 Object detection 분야에서 널리 알려진 Yolo v3를 시작으로 해서 이후의 구현 단계를 예상해 볼 것이다.
<br>

1. 유저가 사진이나 동영상을 해당 서비스에 전달한다.

2. Yolo v3를 통해 해당 사진이나 동영상에서 의류 객체를 탐지한다.

3. DeepLabv3+를 통하여 인식한 객체의 이미지를 분할하여 이미지 레벨이 아닌 픽셀 수준으로 분류한다. 이후, 분류한 이미지 내의 일정 영역을 하나의 덩어리로 묶어낸다.
   (위의 과정을 Semantic segmentation이라 한다.)

4. 분할 과정을 거친 데이터와 DeepFashion2 dataset을 접목하여 정확하고 의류를 분류하고 찾아낸다.

5. 찾아낸 의류의 데이터는 데이터 베이스로 이동한다.

6. 데이터 베이스를 종합적으로 관리하는 Vuex에 보낸다.

7. Vuex 에서 아파치 솔라로 데이터를 보내고, 아파치 솔라의 LTR 알고리즘을 이용하여 보낸 의류 데이터와 매칭 랭크에 따라 관련도가 높은 의류를 User에게 추천한다.

